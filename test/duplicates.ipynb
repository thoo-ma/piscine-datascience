{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE This notebook demonstrate that cleaning the data is not a trivial task.\n",
    "# Even if the operations to perform are trivial (since quite everything is handled by pandas),\n",
    "# there is certainly a thinking process before using those easy and ready to use pandas functions.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine(\"postgresql://trobin:mysecretpassword@localhost:5432/piscineds\")\n",
    "with engine.connect() as connection:\n",
    "    # Load the table\n",
    "    df_items = pd.read_sql_table('items', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, we make sure there is no `None` nor `NaN` values for the `product_id` column\n",
    "# We can see there was no such values since the shape of the dataframe remains the same\n",
    "print(df_items.shape)\n",
    "df_items.dropna(subset=['product_id'], inplace=True)\n",
    "print(df_items.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there would be `None` or `NaN` values for any `product_id` field,\n",
    "# we might see some of them below (they would appear at the bottom)\n",
    "df_items.sort_values('product_id', inplace=True)\n",
    "print(df_items.head(2))\n",
    "print(df_items.tail(2))\n",
    "\n",
    "# All of them would also be printed out this way\n",
    "# df_dup = df[df.duplicated('product_id', keep=False)]\n",
    "df_null = df_items[df_items['product_id'].isnull()]\n",
    "print(df_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So you can see all of this would work, consider a dataframe with such 'not available' values\n",
    "df = pd.DataFrame({\n",
    "    'product_id': [1, None, np.nan],\n",
    "    'category_id': [1, 42, 21],\n",
    "    'brand': ['foo', None, 'bar']\n",
    "})\n",
    "\n",
    "# So you see this actually print NaNs\n",
    "df_null = df[df['product_id'].isnull()]\n",
    "print(df_null)\n",
    "\n",
    "print(df)\n",
    "df.dropna(subset=['product_id'], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondly, we don't want to keep multiple records with the same `produt_id` value\n",
    "# If there would be such, they would also be printed here\n",
    "df_duplicates = df_items[df_items.duplicated('product_id', keep=False)]\n",
    "print(df_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, nothing more has to be done to clean the data\n",
    "# Missing information in other rows is prejudiciable but not critical\n",
    "# However, if there would be such duplicates values for the `product_id` column, we might perform subsequent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id  foo  bar  baz\n",
      "  1  foo None None\n",
      "  1 None  bar None\n",
      "  1 None None  baz\n",
      "  2  foo  bar  baz \n",
      "\n",
      " id foo  bar  baz\n",
      "  1 foo None None\n",
      "  2 foo  bar  baz \n",
      "\n",
      " id  foo  bar  baz\n",
      "  2  foo  bar  baz\n",
      "  1 None None  baz\n",
      "  1 None  bar None\n",
      "  1  foo None None \n",
      "\n",
      " id  foo  bar baz\n",
      "  2  foo  bar baz\n",
      "  1 None None baz \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Just to show this would work if there would be such duplicates, here is a fictionnal demonstration\n",
    "df_ = pd.DataFrame({\n",
    "    'id': [1, 1, 1, 2],\n",
    "    'foo': ['foo', None, None, 'foo'],\n",
    "    'bar': [None, 'bar', None, 'bar'],\n",
    "    'baz': [None, None, 'baz', 'baz']\n",
    "})\n",
    "print(df_.to_string(index=False), \"\\n\")\n",
    "\n",
    "# Here, we only keep the first occurence\n",
    "# this might not be the best occurence to keep,\n",
    "# since it might lack of data in some columns, that removed duplicates didn't.\n",
    "df_dup = df_.drop_duplicates(subset='id')\n",
    "print(df_dup.to_string(index=False), \"\\n\")\n",
    "\n",
    "# Keeping only one non-modified duplicate row, we could choose to prioritize non-missing data of some columns over others\n",
    "# Here, we decide to prioritize data from 'baz' column, then 'bar', then 'foo'\n",
    "df_.sort_values(by=['baz', 'bar', 'foo'], inplace=True)\n",
    "print(df_.to_string(index=False), \"\\n\")\n",
    "\n",
    "# Hence you see the remaining duplicate is the one with the 'baz' column non empty\n",
    "df_dup = df_.drop_duplicates(subset='id')\n",
    "print(df_dup.to_string(index=False), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id  foo  bar  baz\n",
      "  1  foo None None\n",
      "  1 None  bar None\n",
      "  1 None None  baz\n",
      "  2  foo  bar  baz \n",
      "\n",
      " id foo bar baz\n",
      "  1 foo bar baz\n",
      "  2 foo bar baz \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So in this case, the best solution is to edit some rows, precisely to merge some of them.\n",
    "# Let's use the same dataframe\n",
    "df = pd.DataFrame({\n",
    "    'id': [1, 1, 1, 2],\n",
    "    'foo': ['foo', None, None, 'foo'],\n",
    "    'bar': [None, 'bar', None, 'bar'],\n",
    "    'baz': [None, None, 'baz', 'baz']\n",
    "})\n",
    "print(df.to_string(index=False), \"\\n\")\n",
    "\n",
    "# What we could do is merge those three duplicates rows with the same `id` number\n",
    "# by replacing all of their None values by available values from any of other duplicate\n",
    "df = df.groupby('id', as_index=False).first()\n",
    "print(df.to_string(index=False), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
